services:
  ollama:
    # image: ollama/ollama:0.3.14
    image: ollama/ollama:0.4.2
    command: ["serve"]
    restart: always
    volumes:
      - ollama-data:/root/.ollama/
    ports:
      - 10434:11434
    environment:
      OLLAMA_NUM_PARALLEL: 100
      OLLAMA_KEEP_ALIVE: -1
      OLLAMA_MAX_QUEUE: 500
      OLLAMA_MAX_LOADED_MODELS: 10
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1 # alternatively, use `count: all` for all GPUs
              capabilities: [gpu]
      placement:
          constraints:
            - node.labels.gpu == true  # Ensure the node has a GPU label
volumes:
  ollama-data:
    driver: local
    driver_opts:
      type: none
      device: /polus2/gerardinad/projects/aithena/.data/ollama
      o: bind